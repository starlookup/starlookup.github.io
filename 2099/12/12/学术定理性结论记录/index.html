<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>学术定理性结论记录 - 仰望</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="仰望"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="仰望"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="学术论文阅读结论记录 阅读论文过程中，别人的一些结论进行记录，在自己工作中进行引用  差分隐私 在NLP任务中 DP模型的accuracy非常高 鼓励了privacy在语言模型的应用 （与之相对的是CV中DP会产生非常大的accuracy恶化 比如cifar10目前DP限制下只有80%accuracy 而不考虑DP可以轻松95%；ImageNet当时最好的DP accuracy不到50%） 在"><meta property="og:type" content="blog"><meta property="og:title" content="学术定理性结论记录"><meta property="og:url" content="http://lookupes.cn/2099/12/12/%E5%AD%A6%E6%9C%AF%E5%AE%9A%E7%90%86%E6%80%A7%E7%BB%93%E8%AE%BA%E8%AE%B0%E5%BD%95/"><meta property="og:site_name" content="仰望"><meta property="og:description" content="学术论文阅读结论记录 阅读论文过程中，别人的一些结论进行记录，在自己工作中进行引用  差分隐私 在NLP任务中 DP模型的accuracy非常高 鼓励了privacy在语言模型的应用 （与之相对的是CV中DP会产生非常大的accuracy恶化 比如cifar10目前DP限制下只有80%accuracy 而不考虑DP可以轻松95%；ImageNet当时最好的DP accuracy不到50%） 在"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192105970.png"><meta property="og:image" content="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192107732.png"><meta property="og:image" content="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192108732.png"><meta property="og:image" content="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202404091040764.png"><meta property="og:image" content="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/20250524173902.png"><meta property="article:published_time" content="2099-12-11T18:02:02.000Z"><meta property="article:modified_time" content="2025-05-24T09:47:41.329Z"><meta property="article:author" content="Lookup"><meta property="article:tag" content="科研"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192105970.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://lookupes.cn/2099/12/12/%E5%AD%A6%E6%9C%AF%E5%AE%9A%E7%90%86%E6%80%A7%E7%BB%93%E8%AE%BA%E8%AE%B0%E5%BD%95/"},"headline":"学术定理性结论记录","image":["https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192105970.png","https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192107732.png","https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192108732.png","https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202404091040764.png","https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/20250524173902.png"],"datePublished":"2099-12-11T18:02:02.000Z","dateModified":"2025-05-24T09:47:41.329Z","author":{"@type":"Person","name":"Lookup"},"publisher":{"@type":"Organization","name":"仰望","logo":{"@type":"ImageObject","url":"http://lookupes.cn/img/logo.svg"}},"description":"学术论文阅读结论记录 阅读论文过程中，别人的一些结论进行记录，在自己工作中进行引用  差分隐私 在NLP任务中 DP模型的accuracy非常高 鼓励了privacy在语言模型的应用 （与之相对的是CV中DP会产生非常大的accuracy恶化 比如cifar10目前DP限制下只有80%accuracy 而不考虑DP可以轻松95%；ImageNet当时最好的DP accuracy不到50%） 在"}</script><link rel="canonical" href="http://lookupes.cn/2099/12/12/%E5%AD%A6%E6%9C%AF%E5%AE%9A%E7%90%86%E6%80%A7%E7%BB%93%E8%AE%BA%E8%AE%B0%E5%BD%95/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script data-ad-client="Lookup" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="仰望" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2099-12-11T18:02:02.000Z" title="2099/12/12 02:02:02">2099-12-12</time>发表</span><span class="level-item"><time dateTime="2025-05-24T09:47:41.329Z" title="2025/5/24 17:47:41">2025-05-24</time>更新</span><span class="level-item">26 分钟读完 (大约3840个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">学术定理性结论记录</h1><div class="content"><span id="more"></span>

<h3 id="学术论文阅读结论记录"><a href="#学术论文阅读结论记录" class="headerlink" title="学术论文阅读结论记录"></a>学术论文阅读结论记录</h3><blockquote>
<p>阅读论文过程中，别人的一些结论进行记录，在自己工作中进行引用</p>
</blockquote>
<h4 id="差分隐私"><a href="#差分隐私" class="headerlink" title="差分隐私"></a>差分隐私</h4><ol>
<li>在NLP任务中 DP模型的accuracy非常高 鼓励了privacy在语言模型的应用 （与之相对的是CV中DP会产生非常大的accuracy恶化 比如cifar10目前DP限制下只有80%accuracy 而不考虑DP可以轻松95%；ImageNet当时最好的DP accuracy不到50%）</li>
<li>在语言模型上 模型越大性能会越好 比如GPT2中 从4亿参数到8亿参数性能提升很明显 也取得了很多SOTA（但是在CV和推荐系统中 很多时候更大的模型性能会很差 甚至接近random guess 比如CIFAR10的DP best accuracy此前是由四层CNN得到的 而非ResNet）</li>
<li>在多个任务上取得SOTA的超参数是一致的 都是clipping threshold要设置的足够小 并且learning rate需要大一些（此前所有文章都是一个任务调一个clipping threshold 费时费力 并没有出现过像这篇这样一个clipping threshold&#x3D;0.1 贯穿所有任务表现还这么好）<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Li X, Tramer F, Liang P, et al. Large language models can be strong differentially private learners[J]. arXiv preprint arXiv:2110.05679, 2021.</span><br></pre></td></tr></table></figure></li>
<li>差分隐私会使模型无法捕获数据的尾部分布<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Extracting Training Data from Large Language Models</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="成员推理攻击"><a href="#成员推理攻击" class="headerlink" title="成员推理攻击"></a>成员推理攻击</h4><ol>
<li><p>数据增强仅用于提升准确性时，强度低，它无法实现对 MIA 的实质性保护</p>
</li>
<li><p>高强度的数据增强，例如裁剪图像的 90%，会降低准确性，但也会降低风险</p>
</li>
<li><p>流行的标签平滑机制通常会同时增加准确性与风险</p>
</li>
<li><p>准确率越高，风险越高</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">When Does Data Augmentation Help With Membership Inference Attacks?</span><br></pre></td></tr></table></figure>
</li>
<li><p>分布之外的数据更不容易被成员推理</p>
</li>
<li><p>影子模型与训练模型同构，更容易实现攻击</p>
</li>
<li><p>越大的模型越容易被攻击</p>
</li>
<li><p>模型优化器影响不是很大</p>
</li>
<li><p>影子模型采用同样的数据增强会实现更好的攻击效果</p>
</li>
<li><p>数据增强会使的同一个样本在数据集重复出现，会有影响</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Membership Inference Attacks From First principles</span><br></pre></td></tr></table></figure>
</li>
<li><p>成员推理攻击在复杂的数据集上要有效得多（在复杂的数据上更容易过拟合）。模型反演、模型窃取则相反。</p>
</li>
<li><p>模型参数的白盒参数访问对于成员推理攻击没有帮助</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ML-DOCTOR- Holistic Risk Assessment of Inference Attacks Against Machine Learning Models</span><br></pre></td></tr></table></figure>
</li>
<li><p>神经网络模型架构越深，并不更容易受到攻击</p>
</li>
<li><p>具有高维输出（许多类）的任务比具有低维输出的任务更容易受到MIA的影响</p>
</li>
<li><p>过拟合不是成员推理攻击的决定性因素</p>
</li>
<li><p>所有在可推广模型上的实现中等或高成功率的黑匣子 MIA 都需要了解目标样本的真实类别</p>
</li>
<li><p>可推广性模型上的 MIA，对在模型参数有很大影响的记录上，如异常点或分布点，表现会更好</p>
</li>
<li><p>模型泛化能力很大程度上取决于所使用的优化器和正则化方法</p>
</li>
<li><p>优化器的选择对具有强背景信息的黑箱对手的可推广模型的潜在鲁棒性几乎没有影响</p>
</li>
<li><p>对于可推广的模型，唯一显著的差异出现在正确分类的样本和错误分类样本中间，而不是成员与非成员</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SoK: Membership Inference is Harder Than Previously Thought</span><br></pre></td></tr></table></figure>
</li>
<li><p>过拟合模型可以使用一些不典型方式来将该实例识别为训练集成员</p>
</li>
<li><p>MIA 攻击分为单次质询攻击（准确率、置信度、交叉熵、logits）与多次质询攻击(label only)。把成员推理攻击又称之为 metirc-based attack,很有意思的称呼，与我理解不谋而合。</p>
</li>
<li><p>模型对于训练数据周围的数据应该比测试数据周围的数据能够更正确分类</p>
</li>
<li><p>训练数据相较于测试数据距离分类边界应该远</p>
</li>
<li><p>模型应该会对训练数据的数据增强结果更加准确的分类</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MemGuard: Defending against Black-Box MembershipInference Attacks via Adversarial Examples</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>对于 MIA 攻击效果的评估，应该考虑低假阳率（FPR）前提下的真阳率（TPR）</code>，这才是合理的评估指标，平均指标没有任何意义。</p>
</li>
<li><p>对于样本的衡量，文章考虑了两个性质，一个是样本在模型中拟合的难易程度（通过loss可以判断，loss低代表容易拟合），二是样本对于模型的影响，通过对比有无该样本训练的模型对于样本的评估差别，如果没与差别代表样本对于模型影响不大，如果差别很大代表样本本身对模型影响很大。很多攻击只考虑了对于模型影响特别大的样本，而对于影响不大的样本它就没办法判断了。</p>
</li>
<li><p>通过引入 per-class hardness（用来衡量每个类训练的难易程度），没有有效提升低 FPR 下的攻击效果。</p>
</li>
<li><p>通过使用 per-example hardness（用来衡量每个样本训练的难易程度），有效提升低 FPR 下的攻击效果。</p>
</li>
<li><p>过拟合的模型更容易受到攻击，而且更准确的模型更容易受到攻击。</p>
</li>
<li><p>攻击模型与目标模型架构相同时，攻击效果最好，差别越小效果越好。</p>
</li>
<li><p>optimizer（SGD、SGDM、ADAM） 对于攻击效果没有影响。</p>
</li>
<li><p>如果影子模型数据增强方式与目标模型对应时，攻击效果最好。使用的数据增强越强，越难被攻击。</p>
</li>
<li><p>对于本攻击来说，白盒并没有什么改进。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Membership Inference Attacks From First Principles</span><br></pre></td></tr></table></figure>
</li>
<li><p>文章提出成员样本与非成员样本可能最终 loss 差别不大，但是 loss trajectory（loss下降曲线）是不一样的。</p>
</li>
<li><p>蒸馏数据集越大，代表攻击者有更多的辅助数据集，效提升低 FPR 下的攻击效果。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Membership Inference Attacks by Exploiting Loss Trajectory</span><br></pre></td></tr></table></figure>
</li>
<li><p>目标数据集中数据样本的分布对 FNR 的影响很小</p>
</li>
<li><p>训练集数据之间的距离越大，MA攻击概率越高</p>
</li>
<li><p>训练机数据之间的距离对 FNR 影响很小</p>
</li>
<li><p>两个数据集之间的差异越大，攻击成功率越高</p>
</li>
<li><p>两个数据集之间的差异距离对 MIA 的影响大于目标数据集数据间的距离</p>
</li>
<li><p>两个数据集之间的差异距离对 FNR 影响很小<br><img src="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192105970.png"><br><img src="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192107732.png"><br><img src="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202309192108732.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SoK: Comparing Different Membership Inference Attacks with a ComprehensiveBenchmark</span><br></pre></td></tr></table></figure>
</li>
<li><p>文章提出了隐私洋葱理论，通过在特定的隐私攻击下删除最易受攻击的数据，并仅在以前安全的数据上重新训练模型，一组新的示例反过来也容易受到相同的隐私攻击</p>
</li>
<li><p>统计噪声、训练集大小的减少、重复训练示例的存在或模型的有限能力并不能解释洋葱效应。实验表明，洋葱效应可以用去除更极端的异常值后变为异常值的内部值来解释</p>
</li>
<li><p>工作表明，现有隐私审计缺乏“稳定性”，因为由于删除了一小部分训练数据，用户的经验隐私风险可能会发生显著变化。未来隐私审计应该随着底层数据变化而动态更新</p>
</li>
<li><p>也就是说 machine unlearning 会导致其他用户的隐私有更大的风险</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The Privacy Onion Effect: Memorization is Relative</span><br></pre></td></tr></table></figure>
</li>
<li><p>最小揭示隐私的攻击是成员推理攻击，模型反演攻击重构示例子集的代表性视图。模型反转攻击，重建训练数据点</p>
</li>
<li><p>与小模型和中模型比较困惑度策略通常会找到不常见的内容</p>
</li>
<li><p>转小写策略通常会找到有不规则大小写的内容，例如新闻标题(常常是大写单词)或错误日志 (很多大写单词)。</p>
</li>
<li><p>zlib 策略侧重于常见文本，比如新闻标题、许可证文件或重复的字符串</p>
</li>
<li><p>更大的模型会记住更多的训练数据</p>
</li>
<li><p>对于最大的语言模型，只需 33 次即可完全记忆。这意味着即使它仅在单个训练文档中重复多次，也存在记忆风险</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Extracting Training Data from Large Language Models</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="神经网络训练"><a href="#神经网络训练" class="headerlink" title="神经网络训练"></a>神经网络训练</h4><ol>
<li>数据规模可以压制标签中存在的噪声</li>
<li>随着训练数据数量级的增加，任务性能呈对数上升</li>
<li>数据集是一个长尾分布（意思异常值与错误值以及非典型例子占大多数），而对于这些例子模型往往是采用记忆的方法也就是强行背下来的方法，但是这种记忆对于模型达到最优泛化能力是不可获取的</li>
<li>记忆得分高的例子是非典型例子和异常值&#x2F;错误标记的例子的混合，经典例子的记忆得分往往更低</li>
<li><code>在受显著影响的测试示例中，大多数仅受单个训练示例的显著影响</code></li>
<li>互相高影响的数据对，在视觉上有很强的相似性</li>
<li>对于成员推理攻击的防御，减少记忆会影响模型的准确度</li>
<li>在CIFAR-100上删除这两组中的964个独特训练示例可将测试精度降低2.46±0.36%，这与删除11000个随机示例的效果相当</li>
<li>记忆并不是只存在于最后一层<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">What Neural Networks Memorize and Why:Discovering the Long Tail via Influence Estimation</span><br></pre></td></tr></table></figure></li>
<li>针对同样的数据集，采样不同的数据子集，同样的任务，异常点是会改变得，正常点大致相同</li>
<li>异常值包含的规律很傻，很难提取出规律，所以一般模型会直接记忆</li>
<li>更难提取的规律同样会在蒸馏过程中消失，小模型不会记忆太多异常值</li>
<li>提供了一个思路：查看哪些神经元（权重值）与小样本有关，一个神经元（权重值）被很多不同的规律激活，代表就会对多个前向传播的信号有作用；一个神经元（权重值）被激活的很少，代表对异常值有作用<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line">14. 与需要更复杂表示的特征相比，神经网络对学习“简单”特征有很强的偏见</span><br><span class="line">15. 数据集的长尾性质，ML 数据集中有大量的单例示例，特征在训练集中只出现一次，因此神经网络需要记住这些示例</span><br><span class="line">16. 早期学习现象，表明更简单的示例是快速学习的</span><br><span class="line">17. 错误标记的示例可能无法在模型的特定层学习，但它们确实对模型的所有层有很大的影响。对模型所有层的影响比干净的示例高一个数量级</span><br><span class="line">18. 记忆分散在多个层</span><br></pre></td></tr></table></figure>
Can Neural Network Memorization Be Localized?<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">19. 当数据分布是长尾的时，从分布的尾部记忆样本可以帮助模型泛化。</span><br><span class="line">20. 记忆不能简化为过度拟合；事实上，记忆和过度拟合是不同的现象。</span><br><span class="line">21. 许多深度神经网络具有足够的记忆能力来拟合完全随机输入输出关联的大数据集。</span><br><span class="line">22. 记忆可以通过影响估计技术有效地测量，但需要特别注意确保此类估计是准确的。</span><br><span class="line">23. 特别是对于生成模型，通常很难概念化模型记忆的内容（即是否产生与训练记录计数“相似”的输出作为记忆？）评估这一点的一种直观方法是故意插入数据样本，这些样本“预期”被模型记忆，因为它们的“典型性”。然后，根据模型如何再现这些输入作为输出（即生成模型）或这些数据点的性能与数据集其余部分的性能（例如监督学习）相比，测量记忆的能力。</span><br><span class="line">24. 对抗样本是人为非典型的，因此对模型的影响更大（恶意或其他）</span><br><span class="line">25. 越来越多的证据表明，对 ML 的隐私攻击对被记忆的样本更有效。</span><br><span class="line">26. 生成模型中的记忆可以通过自我影响或模型生成与输入数据相似的输出的能力来感知。</span><br><span class="line">27. 如果样本没有再次遇到，则在训练过程中可能会被遗忘。</span><br><span class="line">28. 遗忘可以被人为地诱导为“记住”单个数据点。</span><br><span class="line">29. 差分私有 ML 训练（可证明）可以防止记忆引起的负面特征。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 隐私数据合成</span><br><span class="line"></span><br><span class="line">1. 数据合成领域主要包括 表格数据（Tabular data）、轨迹数据（Trajectory data）、图数据（Graph data）</span><br><span class="line">2. ![](https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202308291712910.png)</span><br><span class="line">3. 对于合成数据方法可以做的工作</span><br><span class="line">    * 隐私攻击：文章认为常见的成员推理攻击本身就是针对 logits 等信息，而在数据合成领域应该有更多的信息可以利用</span><br><span class="line">    * 隐私度量：这是隐私领域通用的一个难题，如何去提出一个通用型隐私量化标准</span><br><span class="line">    * 威胁模型：去研究是否有更合理的威胁模型假设，放宽隐私限制（类似于 label DP）</span><br><span class="line">    * 公平性问题研究：针对合成数据对于不具有代表性的分类可能会有公平性问题解决方案设计</span><br></pre></td></tr></table></figure>
SoK: Privacy-Preserving Data Synthesis<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">#### 大模型 PII 隐私</span><br><span class="line">1. 训练数据中包含的不同类型的 PII 的很大一部分可以通过战略制作的提示披露</span><br><span class="line">2. 通过细化提示，可以访问模型参数，并为 LLM 利用几百个训练数据点，显著放大 PII 泄漏的程度</span><br></pre></td></tr></table></figure>
ProPILE: Probing Privacy Leakage in Large Language Models</li>
</ol>
<p>&#96;&#96;&#96;</p>
<h4 id="数据蒸馏"><a href="#数据蒸馏" class="headerlink" title="数据蒸馏"></a>数据蒸馏</h4><ol>
<li><p>数据蒸馏方法分类<br><img src="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/markdown/202404091040764.png"></p>
</li>
<li><p>当前蒸馏数据无法替代真实数据，其中存在一个限制使用一种模型架构提取的数据不能有效地用于训练不同的模型架构。</p>
</li>
<li><p>将真实数据样本添加到蒸馏数据中可能会降低训练模型的准确性。</p>
</li>
</ol>
<p><img src="https://starlookup-1259639797.cos.ap-chongqing.myqcloud.com/20250524173902.png"></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>学术定理性结论记录</p><p><a href="http://lookupes.cn/2099/12/12/学术定理性结论记录/">http://lookupes.cn/2099/12/12/学术定理性结论记录/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Lookup</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2099-12-12</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-05-24</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%A7%91%E7%A0%94/">科研</a></div><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_telegram"></a><a class="a2a_button_whatsapp"></a><a class="a2a_button_reddit"></a></div><script src="https://static.addtoany.com/menu/page.js" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/alipay.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechat.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2099/08/28/leetcode_%E6%A8%A1%E7%89%88/"><span class="level-item">leetcode 模版</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Lookup"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Lookup</p><p class="is-size-6 is-block">仰望一切，无论是天空中的太阳与月亮，又或者是身边的你</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Xi&#039;an China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">45</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">26</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/starlookup" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/starlookup"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#学术论文阅读结论记录"><span class="level-left"><span class="level-item">1</span><span class="level-item">学术论文阅读结论记录</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#差分隐私"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">差分隐私</span></span></a></li><li><a class="level is-mobile" href="#成员推理攻击"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">成员推理攻击</span></span></a></li><li><a class="level is-mobile" href="#神经网络训练"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">神经网络训练</span></span></a></li><li><a class="level is-mobile" href="#数据蒸馏"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">数据蒸馏</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2099-12-11T18:02:02.000Z">2099-12-12</time></p><p class="title"><a href="/2099/12/12/%E5%AD%A6%E6%9C%AF%E5%AE%9A%E7%90%86%E6%80%A7%E7%BB%93%E8%AE%BA%E8%AE%B0%E5%BD%95/">学术定理性结论记录</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2099-08-27T18:02:03.000Z">2099-08-28</time></p><p class="title"><a href="/2099/08/28/leetcode_%E6%A8%A1%E7%89%88/">leetcode 模版</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-06-05T18:02:02.000Z">2025-06-06</time></p><p class="title"><a href="/2025/06/06/%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%20Tips/">学术写作Tips</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-15T18:02:02.000Z">2024-10-16</time></p><p class="title"><a href="/2024/10/16/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%9A%90%E7%A7%81%E9%97%AE%E9%A2%98%E6%8E%A2%E7%B4%A2/">多模态大模型隐私问题探索</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-11T18:02:02.000Z">2024-10-12</time></p><p class="title"><a href="/2024/10/12/%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E9%80%BB%E8%BE%91/">学术写作逻辑</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2099/12/"><span class="level-start"><span class="level-item">十二月 2099</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2099/08/"><span class="level-start"><span class="level-item">八月 2099</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/06/"><span class="level-start"><span class="level-item">六月 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">十月 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">三月 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">二月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">一月 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">十月 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">九月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">八月 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">七月 2023</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">六月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/05/"><span class="level-start"><span class="level-item">五月 2023</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">四月 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">三月 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">二月 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">十月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">九月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/07/"><span class="level-start"><span class="level-item">七月 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">七月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/English/"><span class="tag">English</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FIgure/"><span class="tag">FIgure</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/xgboost/"><span class="tag">xgboost</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BB%A3%E7%A0%81/"><span class="tag">代码</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%81%E4%B8%9A%E5%AE%89%E5%85%A8/"><span class="tag">企业安全</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"><span class="tag">基础知识</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%9A%90%E7%A7%81/"><span class="tag">大模型隐私</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%89%E5%85%A8/"><span class="tag">安全</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/"><span class="tag">差分隐私</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%91%84%E5%BD%B1/"><span class="tag">摄影</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8/"><span class="tag">数据安全</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/"><span class="tag">数据生成</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E8%92%B8%E9%A6%8F/"><span class="tag">数据蒸馏</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A5%E8%AE%B0/"><span class="tag">日记</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"><span class="tag">服务器</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1-%E5%9B%BD%E9%87%8D%E9%A1%B9%E7%9B%AE/"><span class="tag">知识图谱 国重项目</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E7%A0%94/"><span class="tag">科研</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AF%AE%E7%90%83%E8%A3%81%E5%88%A4/"><span class="tag">篮球裁判</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A8%8B/"><span class="tag">编程</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%8B%B1%E8%AF%AD-%E7%95%99%E5%AD%A6/"><span class="tag">英语 留学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87/"><span class="tag">论文</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87%E8%AF%84%E5%AE%A1/"><span class="tag">论文评审</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%98%85%E8%AF%BB/"><span class="tag">阅读</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">广告</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="Lookup" data-ad-slot="Lookup" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="仰望" height="28"></a><p class="is-size-7"><span>&copy; 2025 Lookup</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><a href="https://beian.miit.gov.cn/" target="_blank">备案号：皖ICP备19019268号</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/starlookup"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>